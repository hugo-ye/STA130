{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2adb4d5f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>ident</th>\n",
       "      <th>type</th>\n",
       "      <th>name</th>\n",
       "      <th>latitude_deg</th>\n",
       "      <th>longitude_deg</th>\n",
       "      <th>elevation_ft</th>\n",
       "      <th>continent</th>\n",
       "      <th>iso_country</th>\n",
       "      <th>iso_region</th>\n",
       "      <th>municipality</th>\n",
       "      <th>scheduled_service</th>\n",
       "      <th>gps_code</th>\n",
       "      <th>iata_code</th>\n",
       "      <th>local_code</th>\n",
       "      <th>home_link</th>\n",
       "      <th>wikipedia_link</th>\n",
       "      <th>keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6523</td>\n",
       "      <td>00A</td>\n",
       "      <td>heliport</td>\n",
       "      <td>Total RF Heliport</td>\n",
       "      <td>40.070985</td>\n",
       "      <td>-74.933689</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-PA</td>\n",
       "      <td>Bensalem</td>\n",
       "      <td>no</td>\n",
       "      <td>K00A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00A</td>\n",
       "      <td>https://www.penndot.pa.gov/TravelInPA/airports...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>323361</td>\n",
       "      <td>00AA</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Aero B Ranch Airport</td>\n",
       "      <td>38.704022</td>\n",
       "      <td>-101.473911</td>\n",
       "      <td>3435.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-KS</td>\n",
       "      <td>Leoti</td>\n",
       "      <td>no</td>\n",
       "      <td>00AA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00AA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6524</td>\n",
       "      <td>00AK</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Lowell Field</td>\n",
       "      <td>59.947733</td>\n",
       "      <td>-151.692524</td>\n",
       "      <td>450.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AK</td>\n",
       "      <td>Anchor Point</td>\n",
       "      <td>no</td>\n",
       "      <td>00AK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00AK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6525</td>\n",
       "      <td>00AL</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Epps Airpark</td>\n",
       "      <td>34.864799</td>\n",
       "      <td>-86.770302</td>\n",
       "      <td>820.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AL</td>\n",
       "      <td>Harvest</td>\n",
       "      <td>no</td>\n",
       "      <td>00AL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00AL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>506791</td>\n",
       "      <td>00AN</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Katmai Lodge Airport</td>\n",
       "      <td>59.093287</td>\n",
       "      <td>-156.456699</td>\n",
       "      <td>80.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AK</td>\n",
       "      <td>King Salmon</td>\n",
       "      <td>no</td>\n",
       "      <td>00AN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00AN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80712</th>\n",
       "      <td>46378</td>\n",
       "      <td>ZZ-0001</td>\n",
       "      <td>heliport</td>\n",
       "      <td>Sealand Helipad</td>\n",
       "      <td>51.894444</td>\n",
       "      <td>1.482500</td>\n",
       "      <td>40.0</td>\n",
       "      <td>EU</td>\n",
       "      <td>GB</td>\n",
       "      <td>GB-ENG</td>\n",
       "      <td>Sealand</td>\n",
       "      <td>no</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://www.sealandgov.org/</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Principality_of_...</td>\n",
       "      <td>Roughs Tower Helipad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80713</th>\n",
       "      <td>307326</td>\n",
       "      <td>ZZ-0002</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Glorioso Islands Airstrip</td>\n",
       "      <td>-11.584278</td>\n",
       "      <td>47.296389</td>\n",
       "      <td>11.0</td>\n",
       "      <td>AF</td>\n",
       "      <td>TF</td>\n",
       "      <td>TF-U-A</td>\n",
       "      <td>Grande Glorieuse</td>\n",
       "      <td>no</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80714</th>\n",
       "      <td>346788</td>\n",
       "      <td>ZZ-0003</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Fainting Goat Airport</td>\n",
       "      <td>32.110587</td>\n",
       "      <td>-97.356312</td>\n",
       "      <td>690.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-TX</td>\n",
       "      <td>Blum</td>\n",
       "      <td>no</td>\n",
       "      <td>87TX</td>\n",
       "      <td>NaN</td>\n",
       "      <td>87TX</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80715</th>\n",
       "      <td>342102</td>\n",
       "      <td>ZZZW</td>\n",
       "      <td>closed</td>\n",
       "      <td>Scandium City Heliport</td>\n",
       "      <td>69.355287</td>\n",
       "      <td>-138.939310</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CA</td>\n",
       "      <td>CA-YT</td>\n",
       "      <td>(Old) Scandium City</td>\n",
       "      <td>no</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ZZZW, ZZZW, ZYW, YK96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80716</th>\n",
       "      <td>313629</td>\n",
       "      <td>ZZZZ</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Satsuma Iōjima Airport</td>\n",
       "      <td>30.784722</td>\n",
       "      <td>130.270556</td>\n",
       "      <td>338.0</td>\n",
       "      <td>AS</td>\n",
       "      <td>JP</td>\n",
       "      <td>JP-46</td>\n",
       "      <td>Mishima</td>\n",
       "      <td>no</td>\n",
       "      <td>RJX7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RJX7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://wikimapia.org/6705190/Satsuma-Iwo-jima-...</td>\n",
       "      <td>SATSUMA,IWOJIMA,RJX7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80717 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id    ident           type                       name  \\\n",
       "0        6523      00A       heliport          Total RF Heliport   \n",
       "1      323361     00AA  small_airport       Aero B Ranch Airport   \n",
       "2        6524     00AK  small_airport               Lowell Field   \n",
       "3        6525     00AL  small_airport               Epps Airpark   \n",
       "4      506791     00AN  small_airport       Katmai Lodge Airport   \n",
       "...       ...      ...            ...                        ...   \n",
       "80712   46378  ZZ-0001       heliport            Sealand Helipad   \n",
       "80713  307326  ZZ-0002  small_airport  Glorioso Islands Airstrip   \n",
       "80714  346788  ZZ-0003  small_airport      Fainting Goat Airport   \n",
       "80715  342102     ZZZW         closed     Scandium City Heliport   \n",
       "80716  313629     ZZZZ  small_airport     Satsuma Iōjima Airport   \n",
       "\n",
       "       latitude_deg  longitude_deg  elevation_ft continent iso_country  \\\n",
       "0         40.070985     -74.933689          11.0       NaN          US   \n",
       "1         38.704022    -101.473911        3435.0       NaN          US   \n",
       "2         59.947733    -151.692524         450.0       NaN          US   \n",
       "3         34.864799     -86.770302         820.0       NaN          US   \n",
       "4         59.093287    -156.456699          80.0       NaN          US   \n",
       "...             ...            ...           ...       ...         ...   \n",
       "80712     51.894444       1.482500          40.0        EU          GB   \n",
       "80713    -11.584278      47.296389          11.0        AF          TF   \n",
       "80714     32.110587     -97.356312         690.0       NaN          US   \n",
       "80715     69.355287    -138.939310           4.0       NaN          CA   \n",
       "80716     30.784722     130.270556         338.0        AS          JP   \n",
       "\n",
       "      iso_region         municipality scheduled_service gps_code iata_code  \\\n",
       "0          US-PA             Bensalem                no     K00A       NaN   \n",
       "1          US-KS                Leoti                no     00AA       NaN   \n",
       "2          US-AK         Anchor Point                no     00AK       NaN   \n",
       "3          US-AL              Harvest                no     00AL       NaN   \n",
       "4          US-AK          King Salmon                no     00AN       NaN   \n",
       "...          ...                  ...               ...      ...       ...   \n",
       "80712     GB-ENG              Sealand                no      NaN       NaN   \n",
       "80713     TF-U-A     Grande Glorieuse                no      NaN       NaN   \n",
       "80714      US-TX                 Blum                no     87TX       NaN   \n",
       "80715      CA-YT  (Old) Scandium City                no      NaN       NaN   \n",
       "80716      JP-46              Mishima                no     RJX7       NaN   \n",
       "\n",
       "      local_code                                          home_link  \\\n",
       "0            00A  https://www.penndot.pa.gov/TravelInPA/airports...   \n",
       "1           00AA                                                NaN   \n",
       "2           00AK                                                NaN   \n",
       "3           00AL                                                NaN   \n",
       "4           00AN                                                NaN   \n",
       "...          ...                                                ...   \n",
       "80712        NaN                         http://www.sealandgov.org/   \n",
       "80713        NaN                                                NaN   \n",
       "80714       87TX                                                NaN   \n",
       "80715        NaN                                                NaN   \n",
       "80716       RJX7                                                NaN   \n",
       "\n",
       "                                          wikipedia_link  \\\n",
       "0                                                    NaN   \n",
       "1                                                    NaN   \n",
       "2                                                    NaN   \n",
       "3                                                    NaN   \n",
       "4                                                    NaN   \n",
       "...                                                  ...   \n",
       "80712  https://en.wikipedia.org/wiki/Principality_of_...   \n",
       "80713                                                NaN   \n",
       "80714                                                NaN   \n",
       "80715                                                NaN   \n",
       "80716  http://wikimapia.org/6705190/Satsuma-Iwo-jima-...   \n",
       "\n",
       "                    keywords  \n",
       "0                        NaN  \n",
       "1                        NaN  \n",
       "2                        NaN  \n",
       "3                        NaN  \n",
       "4                        NaN  \n",
       "...                      ...  \n",
       "80712   Roughs Tower Helipad  \n",
       "80713                    NaN  \n",
       "80714                    NaN  \n",
       "80715  ZZZW, ZZZW, ZYW, YK96  \n",
       "80716   SATSUMA,IWOJIMA,RJX7  \n",
       "\n",
       "[80717 rows x 18 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "url = \"http://ourairports.com/data/airports.csv\"\n",
    "df = pd.read_csv(url)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e92b0ed7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                       0\n",
       "ident                    0\n",
       "type                     0\n",
       "name                     0\n",
       "latitude_deg             0\n",
       "longitude_deg            0\n",
       "elevation_ft         14625\n",
       "continent            38364\n",
       "iso_country            260\n",
       "iso_region               0\n",
       "municipality          5130\n",
       "scheduled_service        0\n",
       "gps_code             38066\n",
       "iata_code            71620\n",
       "local_code           46530\n",
       "home_link            76497\n",
       "wikipedia_link       64302\n",
       "keywords             61620\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e1d4a84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset has 80717 rows and 18 columns.\n"
     ]
    }
   ],
   "source": [
    "#Q2.1\n",
    "rows, columns = df.shape\n",
    "\n",
    "print(f'The dataset has {rows} rows and {columns} columns.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df516583",
   "metadata": {},
   "source": [
    "Q2.2\n",
    "An observation is a single record or entry in a dataset.\n",
    "One observation could be that the location of Total RF Heliport is US.\n",
    "\n",
    "A variable is a feature or characteristic that describes observations. Each column in a data set represents a variable. \n",
    "Variables in my data sets are for example latitude_deg, elevation_ft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bbdb70f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary statistics for numerical columns:\n",
      "                  id  latitude_deg  longitude_deg  elevation_ft\n",
      "count   80717.000000  80717.000000   80717.000000  66092.000000\n",
      "mean   182434.892377     26.028649     -28.512153   1302.556694\n",
      "std    180789.859004     26.143622      85.421729   1670.587210\n",
      "min         2.000000    -89.989444    -179.876999  -1266.000000\n",
      "25%     20332.000000     13.232426     -93.695580    213.000000\n",
      "50%     43186.000000     35.218969     -67.628098    732.000000\n",
      "75%    339417.000000     43.033298      22.794411   1611.000000\n",
      "max    546422.000000     82.750000     179.975700  17372.000000\n"
     ]
    }
   ],
   "source": [
    "#Q3\n",
    "# Summary statistics for numerical columns\n",
    "print(\"\\nSummary statistics for numerical columns:\")\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7d5a1786",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80717, 18)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1a6b6666",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing values in each column:\n",
      "id                       0\n",
      "ident                    0\n",
      "type                     0\n",
      "name                     0\n",
      "latitude_deg             0\n",
      "longitude_deg            0\n",
      "elevation_ft         14625\n",
      "continent            38364\n",
      "iso_country            260\n",
      "iso_region               0\n",
      "municipality          5130\n",
      "scheduled_service        0\n",
      "gps_code             38066\n",
      "iata_code            71620\n",
      "local_code           46530\n",
      "home_link            76497\n",
      "wikipedia_link       64302\n",
      "keywords             61620\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Summary of missing values\n",
    "print(\"\\nMissing values in each column:\")\n",
    "print(df.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7923441c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "continent\n",
      "AS           11658\n",
      "EU           11516\n",
      "SA           11078\n",
      "OC            4041\n",
      "AF            4017\n",
      "AN              43\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df[['continent']].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "297bfb1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iso_country\n",
      "US             31561\n",
      "BR              7204\n",
      "JP              3563\n",
      "CA              3126\n",
      "AU              2677\n",
      "               ...  \n",
      "NF                 1\n",
      "BL                 1\n",
      "NR                 1\n",
      "NU                 1\n",
      "CW                 1\n",
      "Name: count, Length: 244, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df[['iso_country']].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6c7ed178",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iso_country  continent\n",
      "BR           SA           7204\n",
      "JP           AS           3563\n",
      "AU           OC           2677\n",
      "FR           EU           1656\n",
      "GB           EU           1451\n",
      "                          ... \n",
      "GS           AN              1\n",
      "GE           EU              1\n",
      "CX           AS              1\n",
      "CC           AS              1\n",
      "IO           AS              1\n",
      "Name: count, Length: 212, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df[['iso_country', 'continent']].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e45d6477",
   "metadata": {},
   "source": [
    "Q4\n",
    "\n",
    "df.shape tells us the number of all the columns in the dataset regardless of the data type.\n",
    "df.shape also tells us the number of rows with some data entries. It is the maximum amount of rows in the data set. Each of the row may have some missing data.\n",
    "\n",
    "df.describe() returns us the columns that are numerical.\n",
    "df.describe() returns the count of non-empty entries in each column as well as some meaningful statistical analysis. \n",
    "\n",
    "Duet to missing data, is possible that we see a smaller number of rows in some of the variables from df.describe() compared to the shape of the dataset. We might also see fewer columns as some columns are non-numerical."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a65a96",
   "metadata": {},
   "source": [
    "Q5\n",
    "df.shape is an attribute which returns a tuple containing the number of rows and columns whereas calling df.shape() results in error because such a method does not exist.\n",
    "\n",
    "df.describe() is a method call which returns summary statistics whereas df.describe is a reference to the describe function itself. When we write df.describe, we do not call the function, we call an attribute which does not exist.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56156861",
   "metadata": {},
   "source": [
    "ChatGPT SUMMARY #1\n",
    "Here’s a concise summary of our exchanges for your homework assignment:\n",
    "\n",
    "   Initial Request: You asked for an interesting dataset related to airplane traffic at an airport, specifically in a raw CSV format.\n",
    "\n",
    "   First Dataset: I provided a link to a U.S. airport traffic dataset from the Bureau of Transportation Statistics, but the link did not work for you.\n",
    "\n",
    "   Second Attempt: I then shared a link to an OpenSky Network flight dataset, but this link also didn’t work.\n",
    "\n",
    "   Third Attempt: I provided a link to a Kaggle dataset on airline delays and cancellations, but again, it wasn’t accessible.\n",
    "\n",
    "   Final Attempt: Finally, I shared a link to a U.S. Domestic Flights dataset from the Bureau of Transportation Statistics, which should be functional and accessible.\n",
    "\n",
    "Throughout the exchanges, I responded with alternate datasets when previous links failed, ensuring to address your specific request for an airplane traffic dataset.\n",
    "\n",
    "https://chatgpt.com/share/53758f5b-2181-4015-809f-c5a322fea4ec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8a9031f",
   "metadata": {},
   "source": [
    "ChatGPT SUMMARY #2\n",
    "\n",
    "Initial Dataset Analysis:\n",
    "\n",
    "   You began with a dataset from ourairports.com and asked for guidance on providing simple summaries of the columns.\n",
    "    I provided a basic script to load the dataset using pandas, display its first few rows, and generate statistical summaries of the columns (both numerical and categorical), along with information on missing values.\n",
    "    \n",
    "   Key Code Snippet:\n",
    "        data = pd.read_csv(url)\n",
    "    print(data.head())\n",
    "    print(data.info())\n",
    "    print(data.describe())\n",
    "    print(data.describe(include=['object']))\n",
    "    print(data.isnull().sum())\n",
    "    \n",
    "Summaries for Each Column:\n",
    "\n",
    "   You asked for summaries for each column specifically. I suggested using a loop to iterate through each column and generate tailored summaries depending on whether the column was numerical or categorical.\n",
    "    \n",
    "   Key Code Snippet:\n",
    "\n",
    "   for column in data.columns:\n",
    "        col_data = data[column]\n",
    "        if pd.api.types.is_numeric_dtype(col_data):\n",
    "            print(col_data.describe())\n",
    "        else:\n",
    "            print(col_data.value_counts())\n",
    "            \n",
    "Differences Between df.describe() vs df.describe and df.shape() vs df.shape:\n",
    "\n",
    "   You asked about the difference between method calls like df.describe() and attribute access like df.shape.\n",
    "    I explained that df.describe() executes the method to compute statistical summaries, while df.describe is a reference to the method itself. Similarly, df.shape is an attribute that returns the dimensions of the DataFrame, while df.shape() is invalid because shape is not a method.\n",
    "\n",
    "Using .value_counts():\n",
    "\n",
    "   You requested how to use .value_counts() on the dataset.\n",
    "    I demonstrated how to use .value_counts() for categorical columns to count occurrences of each unique value and also provided ways to handle missing values (dropna=False) and normalize the counts (normalize=True).\n",
    "    \n",
    "   Key Code Snippet:\n",
    "\n",
    "   value_counts = data['type'].value_counts()\n",
    "    normalized_counts = data['type'].value_counts(normalize=True)\n",
    "    value_counts_with_nan = data['type'].value_counts(dropna=False)\n",
    "\n",
    "Checking Value Counts of Combinations of Variables:\n",
    "\n",
    "   You wanted to check value counts for combinations of variables (i.e., multiple columns).\n",
    "    I provided two primary methods: using groupby() with size() and using pd.crosstab() for cross-tabulation. These approaches helped count occurrences of combinations of variables like type and iso_country.\n",
    "\n",
    "   Key Code Snippet:\n",
    "\n",
    "   value_counts_combination = data.groupby(['type', 'iso_country']).size()\n",
    "   cross_tab = pd.crosstab(data['type'], data['iso_country'])    \n",
    "    \n",
    "https://chatgpt.com/share/3c335fbd-cf64-4f56-a54f-6d6651a7d746\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef03537",
   "metadata": {},
   "source": [
    "ChatGPT SUMMARY #3\n",
    "Dataset Download and Analysis:\n",
    "\n",
    "   You mentioned downloading a dataset from OurAirports and requested help in determining how many rows and columns it contains.\n",
    "\n",
    "   Due to limitations in accessing external URLs directly, I provided the following pandas code to check the number of rows (observations) and columns (variables):\n",
    "\n",
    "   python\n",
    "\n",
    "   import pandas as pd\n",
    "\n",
    "   #Load the dataset\n",
    "   df = pd.read_csv('path_to_your_downloaded_file/airports.csv')\n",
    "\n",
    "   #Get the number of rows and columns\n",
    "   rows, columns = df.shape\n",
    "\n",
    "   print(f'The dataset has {rows} rows and {columns} columns.')\n",
    "\n",
    "   I advised you to replace the 'path_to_your_downloaded_file/airports.csv' with the actual location of the file on your machine.\n",
    "\n",
    "Explanation of Observations and Variables:\n",
    "\n",
    "   You requested clarification on the terms observations and variables in the context of your dataset:\n",
    "        Observations: Each row in your dataset represents an observation, i.e., a single airport record, which contains details about that airport (e.g., name, location).\n",
    "        Variables: Each column represents a variable, i.e., a characteristic or feature of the airports (e.g., name, city, country, IATA/ICAO codes).\n",
    "    Example:\n",
    "        Rows: The dataset’s rows represent different airports.\n",
    "        Columns: The dataset’s columns represent details such as airport name, city, country, and type of airport.\n",
    "        \n",
    "https://chatgpt.com/share/f5f98631-e2b2-4018-b578-f71b3c31c382"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49fb90e7",
   "metadata": {},
   "source": [
    "Q6\n",
    "Count: The number of non-null entries in the column\n",
    "\n",
    "Mean: The average value of the column that is calculated by summing the values and dividing by the count\n",
    "\n",
    "Std: The standard deviation of the column, which measures the amount of variation from the mean.\n",
    "\n",
    "Min: The minimum/smallest value in the column\n",
    "\n",
    "25%: The first quartile, which is the value below which 25% of the data falls\n",
    "\n",
    "50%: Median: The second quartile, the specific point that divides the data into two equal halves. It is the value below which 50% of the data falls\n",
    "\n",
    "75% The third quartile, which is the value below which 75% of the data falls.\n",
    "\n",
    "Max: The maximum/largest value in the column.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3d5d2a1",
   "metadata": {},
   "source": [
    "Q7\n",
    "7.1 We would prefer df.dropna() when missing values are scattered across many rows and columns. Thus removing rows containing the missing data points won't cause significant data loss.\n",
    "\n",
    "7.2 We would prefer del df['col'] when spcific columns have a high proportion of missing values. Thus removing the entire column will reduce the effect on the rest of the variables and allow us to analyze them. In other words, if the column is the only one containing missing data fora row, we will preserve the row and the other variables that have valuable information.\n",
    "\n",
    "7.3 By dropping the columns before the wrows, we would prevent unneccessary row drops in an instance where a particular column has a high percentage of missing values. Dropping that column prevents the rows from being removed by df.dropna().\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6c82419f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>ident</th>\n",
       "      <th>type</th>\n",
       "      <th>name</th>\n",
       "      <th>latitude_deg</th>\n",
       "      <th>longitude_deg</th>\n",
       "      <th>elevation_ft</th>\n",
       "      <th>continent</th>\n",
       "      <th>iso_country</th>\n",
       "      <th>iso_region</th>\n",
       "      <th>municipality</th>\n",
       "      <th>scheduled_service</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>6536</td>\n",
       "      <td>00HI</td>\n",
       "      <td>heliport</td>\n",
       "      <td>Kaupulehu Heliport</td>\n",
       "      <td>19.832881</td>\n",
       "      <td>-155.978347</td>\n",
       "      <td>43.0</td>\n",
       "      <td>OC</td>\n",
       "      <td>US</td>\n",
       "      <td>US-HI</td>\n",
       "      <td>Kailua-Kona</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>6650</td>\n",
       "      <td>02HI</td>\n",
       "      <td>heliport</td>\n",
       "      <td>K3 Helipad Heliport</td>\n",
       "      <td>21.358390</td>\n",
       "      <td>-157.947890</td>\n",
       "      <td>9.0</td>\n",
       "      <td>OC</td>\n",
       "      <td>US</td>\n",
       "      <td>US-HI</td>\n",
       "      <td>Honolulu</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>4650</td>\n",
       "      <td>03N</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Utirik Airport</td>\n",
       "      <td>11.222219</td>\n",
       "      <td>169.851429</td>\n",
       "      <td>4.0</td>\n",
       "      <td>OC</td>\n",
       "      <td>MH</td>\n",
       "      <td>MH-UTI</td>\n",
       "      <td>Utirik Island</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1174</th>\n",
       "      <td>4777</td>\n",
       "      <td>0TT8</td>\n",
       "      <td>heliport</td>\n",
       "      <td>Dynasty Heliport</td>\n",
       "      <td>14.960012</td>\n",
       "      <td>145.631075</td>\n",
       "      <td>150.0</td>\n",
       "      <td>OC</td>\n",
       "      <td>MP</td>\n",
       "      <td>MP-U-A</td>\n",
       "      <td>San Jose, Tinian</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1772</th>\n",
       "      <td>345303</td>\n",
       "      <td>18HI</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Brandt Field</td>\n",
       "      <td>21.137026</td>\n",
       "      <td>-156.734498</td>\n",
       "      <td>685.0</td>\n",
       "      <td>OC</td>\n",
       "      <td>US</td>\n",
       "      <td>US-HI</td>\n",
       "      <td>Port Saint Joe</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80707</th>\n",
       "      <td>27243</td>\n",
       "      <td>ZYTX</td>\n",
       "      <td>large_airport</td>\n",
       "      <td>Shenyang Taoxian International Airport</td>\n",
       "      <td>41.639801</td>\n",
       "      <td>123.483002</td>\n",
       "      <td>198.0</td>\n",
       "      <td>AS</td>\n",
       "      <td>CN</td>\n",
       "      <td>CN-21</td>\n",
       "      <td>Hunnan, Shenyang</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80709</th>\n",
       "      <td>27244</td>\n",
       "      <td>ZYYJ</td>\n",
       "      <td>medium_airport</td>\n",
       "      <td>Yanji Chaoyangchuan Airport</td>\n",
       "      <td>42.882801</td>\n",
       "      <td>129.451004</td>\n",
       "      <td>624.0</td>\n",
       "      <td>AS</td>\n",
       "      <td>CN</td>\n",
       "      <td>CN-22</td>\n",
       "      <td>Yanji</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80712</th>\n",
       "      <td>46378</td>\n",
       "      <td>ZZ-0001</td>\n",
       "      <td>heliport</td>\n",
       "      <td>Sealand Helipad</td>\n",
       "      <td>51.894444</td>\n",
       "      <td>1.482500</td>\n",
       "      <td>40.0</td>\n",
       "      <td>EU</td>\n",
       "      <td>GB</td>\n",
       "      <td>GB-ENG</td>\n",
       "      <td>Sealand</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80713</th>\n",
       "      <td>307326</td>\n",
       "      <td>ZZ-0002</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Glorioso Islands Airstrip</td>\n",
       "      <td>-11.584278</td>\n",
       "      <td>47.296389</td>\n",
       "      <td>11.0</td>\n",
       "      <td>AF</td>\n",
       "      <td>TF</td>\n",
       "      <td>TF-U-A</td>\n",
       "      <td>Grande Glorieuse</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80716</th>\n",
       "      <td>313629</td>\n",
       "      <td>ZZZZ</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Satsuma Iōjima Airport</td>\n",
       "      <td>30.784722</td>\n",
       "      <td>130.270556</td>\n",
       "      <td>338.0</td>\n",
       "      <td>AS</td>\n",
       "      <td>JP</td>\n",
       "      <td>JP-46</td>\n",
       "      <td>Mishima</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28066 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id    ident            type  \\\n",
       "17       6536     00HI        heliport   \n",
       "154      6650     02HI        heliport   \n",
       "240      4650      03N   small_airport   \n",
       "1174     4777     0TT8        heliport   \n",
       "1772   345303     18HI   small_airport   \n",
       "...       ...      ...             ...   \n",
       "80707   27243     ZYTX   large_airport   \n",
       "80709   27244     ZYYJ  medium_airport   \n",
       "80712   46378  ZZ-0001        heliport   \n",
       "80713  307326  ZZ-0002   small_airport   \n",
       "80716  313629     ZZZZ   small_airport   \n",
       "\n",
       "                                         name  latitude_deg  longitude_deg  \\\n",
       "17                         Kaupulehu Heliport     19.832881    -155.978347   \n",
       "154                       K3 Helipad Heliport     21.358390    -157.947890   \n",
       "240                            Utirik Airport     11.222219     169.851429   \n",
       "1174                         Dynasty Heliport     14.960012     145.631075   \n",
       "1772                             Brandt Field     21.137026    -156.734498   \n",
       "...                                       ...           ...            ...   \n",
       "80707  Shenyang Taoxian International Airport     41.639801     123.483002   \n",
       "80709             Yanji Chaoyangchuan Airport     42.882801     129.451004   \n",
       "80712                         Sealand Helipad     51.894444       1.482500   \n",
       "80713               Glorioso Islands Airstrip    -11.584278      47.296389   \n",
       "80716                  Satsuma Iōjima Airport     30.784722     130.270556   \n",
       "\n",
       "       elevation_ft continent iso_country iso_region      municipality  \\\n",
       "17             43.0        OC          US      US-HI       Kailua-Kona   \n",
       "154             9.0        OC          US      US-HI          Honolulu   \n",
       "240             4.0        OC          MH     MH-UTI     Utirik Island   \n",
       "1174          150.0        OC          MP     MP-U-A  San Jose, Tinian   \n",
       "1772          685.0        OC          US      US-HI    Port Saint Joe   \n",
       "...             ...       ...         ...        ...               ...   \n",
       "80707         198.0        AS          CN      CN-21  Hunnan, Shenyang   \n",
       "80709         624.0        AS          CN      CN-22             Yanji   \n",
       "80712          40.0        EU          GB     GB-ENG           Sealand   \n",
       "80713          11.0        AF          TF     TF-U-A  Grande Glorieuse   \n",
       "80716         338.0        AS          JP      JP-46           Mishima   \n",
       "\n",
       "      scheduled_service  \n",
       "17                   no  \n",
       "154                  no  \n",
       "240                 yes  \n",
       "1174                 no  \n",
       "1772                 no  \n",
       "...                 ...  \n",
       "80707               yes  \n",
       "80709               yes  \n",
       "80712                no  \n",
       "80713                no  \n",
       "80716                no  \n",
       "\n",
       "[28066 rows x 12 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#7.4 Dropping the missing data\n",
    "df_copy = df.copy()\n",
    "del df_copy['gps_code']\n",
    "del df_copy['iata_code']\n",
    "del df_copy['local_code']\n",
    "del df_copy['home_link']\n",
    "del df_copy['wikipedia_link']\n",
    "del df_copy['keywords']\n",
    "\n",
    "df_copy = df_copy.dropna()\n",
    "df_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a81caf4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80717, 18)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape #before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4c230d9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>latitude_deg</th>\n",
       "      <th>longitude_deg</th>\n",
       "      <th>elevation_ft</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>80717.000000</td>\n",
       "      <td>80717.000000</td>\n",
       "      <td>80717.000000</td>\n",
       "      <td>66092.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>182434.892377</td>\n",
       "      <td>26.028649</td>\n",
       "      <td>-28.512153</td>\n",
       "      <td>1302.556694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>180789.859004</td>\n",
       "      <td>26.143622</td>\n",
       "      <td>85.421729</td>\n",
       "      <td>1670.587210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>-89.989444</td>\n",
       "      <td>-179.876999</td>\n",
       "      <td>-1266.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>20332.000000</td>\n",
       "      <td>13.232426</td>\n",
       "      <td>-93.695580</td>\n",
       "      <td>213.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>43186.000000</td>\n",
       "      <td>35.218969</td>\n",
       "      <td>-67.628098</td>\n",
       "      <td>732.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>339417.000000</td>\n",
       "      <td>43.033298</td>\n",
       "      <td>22.794411</td>\n",
       "      <td>1611.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>546422.000000</td>\n",
       "      <td>82.750000</td>\n",
       "      <td>179.975700</td>\n",
       "      <td>17372.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  id  latitude_deg  longitude_deg  elevation_ft\n",
       "count   80717.000000  80717.000000   80717.000000  66092.000000\n",
       "mean   182434.892377     26.028649     -28.512153   1302.556694\n",
       "std    180789.859004     26.143622      85.421729   1670.587210\n",
       "min         2.000000    -89.989444    -179.876999  -1266.000000\n",
       "25%     20332.000000     13.232426     -93.695580    213.000000\n",
       "50%     43186.000000     35.218969     -67.628098    732.000000\n",
       "75%    339417.000000     43.033298      22.794411   1611.000000\n",
       "max    546422.000000     82.750000     179.975700  17372.000000"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe() #before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2edeef8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                       0\n",
       "ident                    0\n",
       "type                     0\n",
       "name                     0\n",
       "latitude_deg             0\n",
       "longitude_deg            0\n",
       "elevation_ft         14625\n",
       "continent            38364\n",
       "iso_country            260\n",
       "iso_region               0\n",
       "municipality          5130\n",
       "scheduled_service        0\n",
       "gps_code             38066\n",
       "iata_code            71620\n",
       "local_code           46530\n",
       "home_link            76497\n",
       "wikipedia_link       64302\n",
       "keywords             61620\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum() #before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6675b789",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28066, 12)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy.shape #After"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3a726fbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>latitude_deg</th>\n",
       "      <th>longitude_deg</th>\n",
       "      <th>elevation_ft</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>28066.000000</td>\n",
       "      <td>28066.000000</td>\n",
       "      <td>28066.000000</td>\n",
       "      <td>28066.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>180775.026651</td>\n",
       "      <td>10.528735</td>\n",
       "      <td>14.921828</td>\n",
       "      <td>1253.357087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>178251.823761</td>\n",
       "      <td>31.376989</td>\n",
       "      <td>71.704789</td>\n",
       "      <td>1645.127677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>-89.989444</td>\n",
       "      <td>-179.876999</td>\n",
       "      <td>-1266.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>31470.250000</td>\n",
       "      <td>-17.634792</td>\n",
       "      <td>-49.259964</td>\n",
       "      <td>174.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>42961.500000</td>\n",
       "      <td>4.004589</td>\n",
       "      <td>8.946570</td>\n",
       "      <td>676.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>335650.500000</td>\n",
       "      <td>42.412031</td>\n",
       "      <td>54.960614</td>\n",
       "      <td>1738.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>546422.000000</td>\n",
       "      <td>81.150000</td>\n",
       "      <td>179.975700</td>\n",
       "      <td>17372.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  id  latitude_deg  longitude_deg  elevation_ft\n",
       "count   28066.000000  28066.000000   28066.000000  28066.000000\n",
       "mean   180775.026651     10.528735      14.921828   1253.357087\n",
       "std    178251.823761     31.376989      71.704789   1645.127677\n",
       "min         2.000000    -89.989444    -179.876999  -1266.000000\n",
       "25%     31470.250000    -17.634792     -49.259964    174.000000\n",
       "50%     42961.500000      4.004589       8.946570    676.000000\n",
       "75%    335650.500000     42.412031      54.960614   1738.000000\n",
       "max    546422.000000     81.150000     179.975700  17372.000000"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy.describe() #after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "24f45470",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                   0\n",
       "ident                0\n",
       "type                 0\n",
       "name                 0\n",
       "latitude_deg         0\n",
       "longitude_deg        0\n",
       "elevation_ft         0\n",
       "continent            0\n",
       "iso_country          0\n",
       "iso_region           0\n",
       "municipality         0\n",
       "scheduled_service    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy.isna().sum() #after"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0189b261",
   "metadata": {},
   "source": [
    "7.4 I dropped a number of string-type columns for which the data points are more or less unique and are not repetitive. These columns all had a great number of missing data points. Such columns are for example, wikipedia_link, for which comparison and statistical analysis are irrelevant. By dropping them first before dropping rows, I likely saved a significant number of rows with interesting data for statistical analysis.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f2b1720b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   survived  pclass     sex   age  sibsp  parch     fare embarked  class  \\\n",
      "0         0       3    male  22.0      1      0   7.2500        S  Third   \n",
      "1         1       1  female  38.0      1      0  71.2833        C  First   \n",
      "2         1       3  female  26.0      0      0   7.9250        S  Third   \n",
      "3         1       1  female  35.0      1      0  53.1000        S  First   \n",
      "4         0       3    male  35.0      0      0   8.0500        S  Third   \n",
      "\n",
      "     who  adult_male deck  embark_town alive  alone  \n",
      "0    man        True  NaN  Southampton    no  False  \n",
      "1  woman       False    C    Cherbourg   yes  False  \n",
      "2  woman       False  NaN  Southampton   yes   True  \n",
      "3  woman       False    C  Southampton   yes  False  \n",
      "4    man        True  NaN  Southampton    no   True  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 15 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   survived     891 non-null    int64  \n",
      " 1   pclass       891 non-null    int64  \n",
      " 2   sex          891 non-null    object \n",
      " 3   age          714 non-null    float64\n",
      " 4   sibsp        891 non-null    int64  \n",
      " 5   parch        891 non-null    int64  \n",
      " 6   fare         891 non-null    float64\n",
      " 7   embarked     889 non-null    object \n",
      " 8   class        891 non-null    object \n",
      " 9   who          891 non-null    object \n",
      " 10  adult_male   891 non-null    bool   \n",
      " 11  deck         203 non-null    object \n",
      " 12  embark_town  889 non-null    object \n",
      " 13  alive        891 non-null    object \n",
      " 14  alone        891 non-null    bool   \n",
      "dtypes: bool(2), float64(2), int64(4), object(7)\n",
      "memory usage: 92.4+ KB\n",
      "None\n",
      "         survived      pclass         age       sibsp       parch        fare\n",
      "count  891.000000  891.000000  714.000000  891.000000  891.000000  891.000000\n",
      "mean     0.383838    2.308642   29.699118    0.523008    0.381594   32.204208\n",
      "std      0.486592    0.836071   14.526497    1.102743    0.806057   49.693429\n",
      "min      0.000000    1.000000    0.420000    0.000000    0.000000    0.000000\n",
      "25%      0.000000    2.000000   20.125000    0.000000    0.000000    7.910400\n",
      "50%      0.000000    3.000000   28.000000    0.000000    0.000000   14.454200\n",
      "75%      1.000000    3.000000   38.000000    1.000000    0.000000   31.000000\n",
      "max      1.000000    3.000000   80.000000    8.000000    6.000000  512.329200\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "url = 'https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv'\n",
    "titanic = pd.read_csv(url)\n",
    "\n",
    "print (titanic.head())\n",
    "print (titanic.info())\n",
    "print(titanic.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ac352612",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pclass</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>216.0</td>\n",
       "      <td>84.154687</td>\n",
       "      <td>78.380373</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.92395</td>\n",
       "      <td>60.2875</td>\n",
       "      <td>93.5</td>\n",
       "      <td>512.3292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>184.0</td>\n",
       "      <td>20.662183</td>\n",
       "      <td>13.417399</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.00000</td>\n",
       "      <td>14.2500</td>\n",
       "      <td>26.0</td>\n",
       "      <td>73.5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>491.0</td>\n",
       "      <td>13.675550</td>\n",
       "      <td>11.778142</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.75000</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>15.5</td>\n",
       "      <td>69.5500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        count       mean        std  min       25%      50%   75%       max\n",
       "pclass                                                                     \n",
       "1       216.0  84.154687  78.380373  0.0  30.92395  60.2875  93.5  512.3292\n",
       "2       184.0  20.662183  13.417399  0.0  13.00000  14.2500  26.0   73.5000\n",
       "3       491.0  13.675550  11.778142  0.0   7.75000   8.0500  15.5   69.5500"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Q8.1\n",
    "titanic.groupby(\"pclass\")[\"fare\"].describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53610b0d",
   "metadata": {},
   "source": [
    "Q8.1 I have grouped the passengers by \"pclass and chosen to analyze the summaries for column \"fare\". Thus we can analyze the summaries for each of the passenger class with regards to the fare they paid for the trip. We can observe that the higher the class (pclass is small), the greater the fare. Interestingly the summary also indicates that the standard deviation for the highest class is the greatest. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d9f7506b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    714.000000\n",
       "mean      29.699118\n",
       "std       14.526497\n",
       "min        0.420000\n",
       "25%       20.125000\n",
       "50%       28.000000\n",
       "75%       38.000000\n",
       "max       80.000000\n",
       "Name: age, dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic[\"age\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4cc8a263",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.42</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.67</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.75</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.83</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.92</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70.00</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70.50</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71.00</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74.00</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80.00</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>88 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      count unique     top freq\n",
       "age                            \n",
       "0.42      1      1    male    1\n",
       "0.67      1      1    male    1\n",
       "0.75      2      1  female    2\n",
       "0.83      2      1    male    2\n",
       "0.92      1      1    male    1\n",
       "...     ...    ...     ...  ...\n",
       "70.00     2      1    male    2\n",
       "70.50     1      1    male    1\n",
       "71.00     2      1    male    2\n",
       "74.00     1      1    male    1\n",
       "80.00     1      1    male    1\n",
       "\n",
       "[88 rows x 4 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic.groupby(\"age\")[\"sex\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed311ad5",
   "metadata": {},
   "source": [
    "Q8.2\n",
    "The count for df.describe() captures the non-missing values in each column, irrespective of the other columns. Count may vary from a column to another based on the number of missing data in each one.\n",
    "\n",
    "Whereas the count for df.groupby(\"col1\")[\"col2\"].describe() captures the non-missing values of col2 in each group defined by the values in col1. \n",
    "The primary function of count used in conjunction with group_by is to see the distribution of the count across the groups evaluating."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89217750",
   "metadata": {},
   "source": [
    "Q8.3\n",
    "\n",
    "A. \n",
    "\n",
    "Both the first result of Google search and ChatGPT suggested me that the issue was in the import cell for python library pandas and suggested to fix it. Both of them suggested code to fix it as well.\n",
    "\n",
    "B.\n",
    "\n",
    "CHATGPT\n",
    "By opening a fresh chatgpt session, I made sure that the conversation was free of my previous context working with a dataset called titanic.csv. ChatGPT provided me that the error suggests that the URL I'm trying does not exist, and provided me the correct link, fixing \"titanics.csv\" to \"titanic.csv\"\n",
    "\n",
    "Google\n",
    "Whereas the error code \"HTTP Error 404: Not Found\" on google search provided a variety of generic answers, such as network connection errors. \n",
    "\n",
    "I conclude that it would have been significantly easier to use ChatGPT to debug this error in a real environment.\n",
    "\n",
    "C.\n",
    "\n",
    "CHATGPT\n",
    "By pasting the entire error to chatGPT, the solution told me that the issue is that I have not initialized or properly assigned the variable DF. It does not suggest me that the error is in a typo. However, I believe the resulting error hunting is easy and leads to inferring the real issue with my code. \n",
    "\n",
    "GOOGLE\n",
    "Similarly, the second result on Google Search suggested me that the error is that I am trying to use a DataFrame object df before it has been defined.\n",
    "\n",
    "In this example, the two methods were equally applicable to provide a partial solution to debug the problem.\n",
    "\n",
    "D.\n",
    "\n",
    "CHATGPT\n",
    "ChatGPT quickly identified the error code that is SyntaxError and provided me the code to fix the missing bracket.\n",
    "\n",
    "GOOGLE\n",
    "Google search did not quickly provide a solution as the answers varied between different cases of \"Incomplete Input\". \n",
    "\n",
    "Therefore I conclude that it is due to ChatGPT being able use the context, it was clearly fared more sufficient at fixing the error.\n",
    "\n",
    "E.\n",
    "\n",
    "CHATGPT\n",
    "ChatGPT quickly identified that I had written groupdby instead of groupby, and suggested a fixed code.\n",
    "\n",
    "GOOGLE\n",
    "While the first entries on my google search did not provide the precise same error I had, there were entries where people discussed mistyping \"groupby\" in other ways. Moreover, one of the first entries was also the proper documentation for function \"groupby\", Therefore it was sufficiently easy for me to debug the error with Google.\n",
    "\n",
    "CHATGPT was easy but Google search was sufficient.\n",
    "\n",
    "\n",
    "F.\n",
    "\n",
    "For the error in the first column (\"Sex\"), both the first result on Google and ChatGPT suggest that the error is in a typo in my key. It was a tie.\n",
    "\n",
    "For the error in the second column (\"Age\"), ChatGPT identified the error 'Column not found: Age' quickly, and using its analysis, it suggested me that the error was in case sensitivity and suggested me the write strip of code to spell the column key correctly.\n",
    "\n",
    "The first entries on my google search also suggested me that the keyerror occurs when I misspell a column/row name. However, there were entries on my google search with more advanced issues with the column error. \n",
    "\n",
    "These other entries on Google might confuse me, whereas the ChatGPT result was straightforward.\n",
    "\n",
    "G. \n",
    "\n",
    "ChatGPT:\n",
    "Entering the error name to ChatGPT, I quickly got a solution to check if there is an error in my variable or if there are missing quotation marks. This is true for both columns (sex), [age]. \n",
    "\n",
    "GOOGLE\n",
    "A Google search of the error code returns many forum posts where there are more advanced and unique cases of name error. It is not as apparent for my specific as the result from ChatGPT.\n",
    "\n",
    "I believe that for code related debugging, I would use ChatGPT more having done the analysis this exercise.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed49e660",
   "metadata": {},
   "source": [
    "Q9 YES, I used the internet and ChatGPT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "292463ad",
   "metadata": {},
   "source": [
    "ChatGPT SUMMARY #4\n",
    "Here is a summary of our interactions regarding your homework assignment on data analysis using Python and pandas:\n",
    "\n",
    "Topic: Data Analysis with Python (pandas) and Summary Statistics\n",
    "\n",
    "   Working with the Titanic Dataset:\n",
    "        You mentioned working on data analysis using Python and pandas, focusing on the Titanic dataset, which contains some missing values.\n",
    "    Understanding df.describe() Output in pandas:\n",
    "        You asked for definitions and explanations of the summary statistics provided by the df.describe() method in pandas.\n",
    "        I explained the following key summary statistics:\n",
    "            Count: Number of non-null entries in a column.\n",
    "            Mean: The average value of a column.\n",
    "            Std: Standard deviation, showing how much variation exists from the mean.\n",
    "            Min: The smallest value in the column.\n",
    "            25% (First Quartile): Value below which 25% of the data falls.\n",
    "            50% (Median or Second Quartile): Middle value when data is sorted.\n",
    "            75% (Third Quartile): Value below which 75% of the data falls.\n",
    "            Max: The largest value in the column.\n",
    "        These definitions explain the key statistics that help understand data distribution and variability in numerical datasets.\n",
    "\n",
    "https://chatgpt.com/share/c5c755b1-2343-4913-affe-757510c666f4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38151286",
   "metadata": {},
   "source": [
    "ChatGPT SUMMARY #5\n",
    "\n",
    "Summary of Interactions on Missing Data in Python (Pandas)\n",
    "\n",
    "   Handling Missing Data Efficiently:\n",
    "        We discussed two primary methods for dealing with missing data: df.dropna() and del df['col'].\n",
    "        df.dropna() is used to remove rows with missing values, which is efficient when missing data is scattered across rows and columns. It allows you to keep most of the columns intact while only removing the rows with missing data.\n",
    "        del df['col'] is useful when a column has a high percentage of missing values and is not useful for analysis. Removing such columns helps preserve the integrity of the remaining dataset.\n",
    "\n",
    "   When to Use df.dropna() vs. del df['col']:\n",
    "        Use df.dropna() when missing values are spread across rows, and removing specific rows won't significantly reduce the dataset’s size or quality. It helps retain more columns while focusing on row-level data cleaning.\n",
    "        Use del df['col'] when specific columns have too many missing values (e.g., >70%), making them irrelevant or unusable. Deleting the entire column helps preserve rows for analysis without dealing with too many imputations or unnecessary bias.\n",
    "\n",
    "   Importance of the Order:\n",
    "        Applying del df['col'] before df.dropna() is essential because:\n",
    "            It avoids the unnecessary removal of rows due to missing values in columns that will eventually be deleted.\n",
    "            This order helps retain more rows that contain valid data in other columns.\n",
    "            It streamlines the data-cleaning process and improves performance by working with a smaller, more meaningful dataset after column deletion.\n",
    "\n",
    "   Efficient Workflow:\n",
    "        We explored a typical workflow for combining these methods:\n",
    "            First, delete irrelevant or highly missing columns using del df['col'].\n",
    "            Then, apply df.dropna() to remove rows with missing values in the remaining relevant columns.\n",
    "        This sequence ensures that the most useful data is retained, maximizing the non-missing data in the dataset while efficiently handling missing data issues.\n",
    "\n",
    "https://chatgpt.com/share/dbc4ee83-fa60-4f4e-b8ba-fc47c780d1bc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6302a0bb",
   "metadata": {},
   "source": [
    "ChatGPT SUMMARY #6\n",
    "\n",
    "1. Initial Titanic Data Analysis:\n",
    "\n",
    "    User mentioned working on simple summary analyses of the Titanic dataset, including handling missing values.\n",
    "    Assistant provided an example code snippet for initial data analysis using pandas, including pd.read_csv(), df.head(), df.info(), and df.describe() to check the data's structure, missing values, and summary statistics.\n",
    "\n",
    "2. Understanding df.groupby(\"col1\")[\"col2\"].describe():\n",
    "\n",
    "    User inquired about what the code df.groupby(\"col1\")[\"col2\"].describe() does.\n",
    "    Assistant explained that this code groups the DataFrame by the unique values in col1, selects col2 from each group, and then computes summary statistics (e.g., count, mean, std) for col2 within each group.\n",
    "\n",
    "3. Difference in count Values:\n",
    "\n",
    "    User noted that the count values in df.describe() and df.groupby(\"col1\")[\"col2\"].describe() represent different aspects of data analysis.\n",
    "    Assistant clarified that in df.describe(), count represents the number of non-missing values in each column overall. In df.groupby(\"col1\")[\"col2\"].describe(), count represents the number of non-missing values in col2 within each group defined by col1.\n",
    "\n",
    "4. Primary Function of count in groupby:\n",
    "\n",
    "    User pointed out that count in groupby has a primary function beyond addressing missing values, which is to summarize group sizes.\n",
    "    Assistant explained that the count in groupby shows the size of each group and is crucial for understanding data distribution across groups, highlighting disparities, and providing context for further statistical analysis.\n",
    "    \n",
    "https://chatgpt.com/share/359c1635-753a-4879-8076-a1936ef0e8e6\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c74da8",
   "metadata": {},
   "source": [
    "ChatGPT SUMMARY #7\n",
    "\n",
    "    User's Work Context:\n",
    "        The user is working on data analysis using Python and pandas.\n",
    "        Their current focus is on the Titanic dataset, which involves handling missing values.\n",
    "\n",
    "    Issue Encountered:\n",
    "        The user encountered a NameError indicating that the name 'pd' is not defined in their code.\n",
    "\n",
    "    Solution Provided:\n",
    "        I suggested that the user should ensure they have imported pandas with import pandas as pd at the beginning of their script or notebook. This line of code allows them to use pd as an alias for pandas.\n",
    "        I also advised them to check if pd might have been redefined elsewhere in their code if the import statement is present but the error persists.\n",
    "        \n",
    "https://chatgpt.com/share/34b6fca7-8629-4dbf-8b07-21619ae20741"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7391c278",
   "metadata": {},
   "source": [
    "ChatGPT SUMMARY #8\n",
    "\n",
    "Summary of Interactions:\n",
    "\n",
    "    Initial Issue:\n",
    "        The user encountered an HTTPError: HTTP Error 404: Not Found when trying to read the Titanic dataset from a URL using pandas.\n",
    "        The code used was:\n",
    "\n",
    "        python\n",
    "\n",
    "    import pandas as pd\n",
    "    url = 'https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanics.csv'\n",
    "    titanic = pd.read_csv(url)\n",
    "    print(titanic.head())\n",
    "    print(titanic.info())\n",
    "\n",
    "Resolution Provided:\n",
    "\n",
    "    I identified that the URL in the code was incorrect, pointing out that the correct URL should be:\n",
    "\n",
    "    python\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv'\n",
    "\n",
    "The corrected code snippet was:\n",
    "\n",
    "python\n",
    "\n",
    "        import pandas as pd\n",
    "        url = 'https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv'\n",
    "        titanic = pd.read_csv(url)\n",
    "\n",
    "        print(titanic.head())\n",
    "        print(titanic.info())\n",
    "\n",
    "    Follow-Up Issue:\n",
    "        The user then encountered a KeyError when working with the DataFrame.\n",
    "        I requested additional information about the code and error message to diagnose the issue further.\n",
    "\n",
    "https://chatgpt.com/share/62c609fd-7875-475b-9dc9-00972c819f74"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7434fe77",
   "metadata": {},
   "source": [
    "ChatGPT SUMMARY #9\n",
    "\n",
    "Error: NameError: name 'df' is not defined:\n",
    "\n",
    "    This occurred because the variable df was not initialized before use. I provided guidance on how to properly load the Titanic dataset into a pandas DataFrame using pd.read_csv().\n",
    "\n",
    "Solution:\n",
    "\n",
    "python\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.read_csv('titanic.csv')\n",
    "\n",
    "Error: SyntaxError: incomplete input due to incorrect brackets:\n",
    "\n",
    "    You shared this code:\n",
    "\n",
    "    python\n",
    "\n",
    "    titanic.groupby(\"sex\"[\"fare\"].describe()\n",
    "\n",
    "    The error stemmed from a missing closing parenthesis and incorrect use of brackets.\n",
    "\n",
    "Corrected code:\n",
    "\n",
    "python\n",
    "\n",
    "titanic.groupby(\"sex\")[\"fare\"].describe()\n",
    "\n",
    "Error: AttributeError: 'DataFrame' object has no attribute 'groupdby':\n",
    "\n",
    "    This happened due to a typo where groupdby was used instead of groupby.\n",
    "\n",
    "Corrected code:\n",
    "\n",
    "python\n",
    "\n",
    "titanic.groupby(\"sex\")[\"age\"].describe()\n",
    "\n",
    "Error: KeyError: 'Column not found: Age':\n",
    "\n",
    "    This error occurred because the column \"Age\" was referenced with incorrect casing. Pandas column names are case-sensitive, and the correct column name might be \"age\".\n",
    "\n",
    "Solution: Check column names using:\n",
    "\n",
    "python\n",
    "\n",
    "print(titanic.columns)\n",
    "\n",
    "Then use the correct case for the column name:\n",
    "\n",
    "python\n",
    "\n",
    "titanic.groupby(\"sex\")[\"age\"].describe()\n",
    "\n",
    "Error: NameError: name 'sex' is not defined:\n",
    "\n",
    "    This happened because you passed sex without quotation marks when referencing the column. Column names should be strings.\n",
    "\n",
    "Corrected code:\n",
    "\n",
    "python\n",
    "\n",
    "    titanic_df.groupby(\"sex\")[\"age\"].describe()\n",
    "\n",
    "This summary outlines the progression of issues and their solutions regarding your work with the Titanic dataset in pandas. Let me know if you need further adjustments or explanations!\n",
    "\n",
    "https://chatgpt.com/share/68da9de1-272c-42e6-949e-8743c8764bcb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebadbc14",
   "metadata": {},
   "outputs": [],
   "source": [
    "ChatGPT SUMMARY #10\n",
    "\n",
    "Interaction Summary:\n",
    "\n",
    "    Issue with 'sex' Column:\n",
    "        The user encountered a NameError: name 'sex' is not defined.\n",
    "        Possible causes discussed:\n",
    "            Case sensitivity (Sex vs. sex).\n",
    "            The need to use quotes to access columns (e.g., df['sex']).\n",
    "            Ensuring the correct DataFrame name is used.\n",
    "\n",
    "    Issue with 'age' Column:\n",
    "        The user encountered a NameError: name 'age' is not defined.\n",
    "        Possible causes discussed:\n",
    "            Similar case sensitivity issue (e.g., Age vs. age).\n",
    "            Correct access method for the column (e.g., df['Age'] or df.Age).\n",
    "            Ensuring that the DataFrame is defined and contains the 'Age' column.\n",
    "            \n",
    "https://chatgpt.com/share/66e34576-e3d8-800d-8e63-17341f70a778"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
